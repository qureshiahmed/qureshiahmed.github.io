<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" /> 
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Ahmed H. Qureshi</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
  <div class="menu-item"><a href="index.html" class="current">Home</a></div>
  <div class="menu-item"><a href="publication.html">Publications</a></div>
  <div class="menu-item"><a href="CV_Ahmed.pdf">CV</a></div>
  
  <div class="menu-category">Links</div>
  <div class="menu-item"><a href="https://scholar.google.com/citations?user=Lkrx2SkAAAAJ&hl=en">Google&nbsp;Scholar</a></div>
  <div class="menu-item"><a href="index.html#ju">Join&nbsp;Us</a></div></td>
<td id="layout-content">
<div id="toptitle">
<h1>Publications</h1>
</div>
<h3>Preprints</h3>
<ul> 
<li><p><b>Motion Planning Transformers: One Model to Plan Them All</b> <br />
  J.J.Johnson, L.Li, A.H.Qureshi, and M.C.Yip<br />
  arXiv:2106.02791 [cs.RO]
 [<a href="https://arxiv.org/abs/2106.02791" target=&ldquo;blank&rdquo;>arXiv</a>]
</p>
</li>    
</ul> 
<h3>2021</h3>
<ul> 
<li><p><b>NeRP: Neural Rearrangement Planning for Unknown Objects</b> <br />
    A.H.Qureshi, A.Mousavian, C.Paxton, M.C.Yip, and D.Fox <br />
    Robotics: Science and Systems, 2021.
  [<a href="https://roboticsconference.org/program/papers/072/" target=&ldquo;blank&rdquo;>paper</a>] [<a href="https://arxiv.org/abs/2106.01352" target=&ldquo;blank&rdquo;>arXiv</a>] [<a href="https://youtu.be/CJb1IzH94eo" target=&ldquo;blank&rdquo;>project</a>]
  </p>
</li><br/>    
<li><p><b>Constrained Motion Planning Networks X</b> <br />
A.H.Qureshi, J.Dong, A.Baig, and M.C.Yip<br />
IEEE Transactions on Robotics, 2021.
[<a href="https://ieeexplore.ieee.org/document/9501956" target=&ldquo;blank&rdquo;>paper</a>] [<a href="https://arxiv.org/abs/2010.08707" target=&ldquo;blank&rdquo;>arXiv</a>] [<a href="https://sites.google.com/view/compnetx/home" target=&ldquo;blank&rdquo;>project</a>]
</p>
</li><br/>
<li><p><b>MPC-MPNet: Model-Predictive Motion Planning Networks for Fast, Near-Optimal Planning under Kinodynamic Constraints</b> <br />
  L.Li, Y.Miao, A.H.Qureshi, and M.C.Yip<br />
  IEEE Robotics and Automation Letters, 2021.
[<a href="https://ieeexplore.ieee.org/document/9384209" target=&ldquo;blank&rdquo;>paper</a>] [<a href="https://arxiv.org/abs/2101.06798" target=&ldquo;blank&rdquo;>arXiv</a>] [<a href="https://sites.google.com/view/mpc-mpnet" target=&ldquo;blank&rdquo;>project</a>]
</p>
</li>
</ul>
<h3>2020</h3>
<ul>
<li><p><b>Neural Manipulation Planning on Constraint Manifolds</b> <br />
  A.H.Qureshi, J.Dong, A.Choe, and M.C.Yip<br />
  IEEE Robotics and Automation Letters, 2020.
[<a href="https://ieeexplore.ieee.org/document/9143433" target=&ldquo;blank&rdquo;>paper</a>] [<a href="https://arxiv.org/abs/2008.03787" target=&ldquo;blank&rdquo;>arXiv</a>] [<a href="https://sites.google.com/view/constrainedmpnet/home" target=&ldquo;blank&rdquo;>project</a>]
</p>
</li><br/>

<li><p><b>Composing Task Agnostic Policies via Deep Reinforcement Learning</b> <br />
  A.H.Qureshi, J.J.Johnson, Y.Qin, T.West, B.Boots, and M.C.Yip<br />
  International Conference on Representation Learning (ICLR), 2020.
[<a href="https://openreview.net/forum?id=H1ezFREtwH" target=&ldquo;blank&rdquo;>paper</a>] [<a href="https://arxiv.org/abs/1905.10681" target=&ldquo;blank&rdquo;>arXiv</a>] [<a href="https://sites.google.com/view/compositional-rl" target=&ldquo;blank&rdquo;>project</a>]
</p>
</li><br/>

<li><p><b>Dynamically Constrained Motion Planning Networks for Non-Holonomic Robots</b> <br />
  J.Johnson, L.Li, F.Liu, A.H.Qureshi, and M.C.Yip<br />
  IEEE/RSJ International Conference on Intelligent Robot and Systems (IROS), 2020.
[<a href="https://ieeexplore.ieee.org/document/9143433" target=&ldquo;blank&rdquo;>paper</a>] [<a href="https://arxiv.org/abs/2008.05112" target=&ldquo;blank&rdquo;>arXiv</a>] [<a href="https://github.com/ucsdarclab/mpnet_local_planner" target=&ldquo;blank&rdquo;>project</a>]
</p>
</li><br/>

<li><p><b>Active Continual Learning for Planning and Navigation</b> <br />
  A.H.Qureshi, Y.Miao, and M.C.Yip<br />
  ICML Workshop on Real World Experiment Design and Active Learning, 2020
</p>
</li><br/>


<li><p><b>Motion Planning Networks: Bridging the Gap Between Learning-based and Classical Motion Planners</b> <br />
  A.H.Qureshi, Y.Miao, A.Simeonov, and M.C.Yip<br />
  IEEE Transactions on Robotics, 2020.
[<a href="https://ieeexplore.ieee.org/document/9154607" target=&ldquo;blank&rdquo;>paper</a>] [<a href="https://arxiv.org/abs/1907.06013" target=&ldquo;blank&rdquo;>arXiv</a>] [<a href="https://sites.google.com/view/mpnet/home" target=&ldquo;blank&rdquo;>project</a>]
</p>
</li><br/>
</ul>
<h3>2019</h3>
<ul>
<li><p><b>Adversarial Imitation Via Variational Inverse Reinforcement Learning</b> <br />
  A.H.Qureshi, B. Boots, and M.C.Yip<br />
  International Conference on Representation Learning (ICLR), 2019.
[<a href="https://openreview.net/forum?id=HJlmHoR5tQ" target=&ldquo;blank&rdquo;>paper</a>] [<a href="https://arxiv.org/abs/1809.06404" target=&ldquo;blank&rdquo;>arXiv</a>] [<a href="https://sites.google.com/view/eairl" target=&ldquo;blank&rdquo;>project</a>]
</p>
</li><br/>


<li><p><b>Motion Planning Networks</b> <br />
  A.H.Qureshi, A.Simeonov, M.J.Bency, and M.C.Yip<br />
  IEEE/RAS International Conference on Robotics and Automation (ICRA), 2019.
[<a href="https://ieeexplore.ieee.org/document/8793889" target=&ldquo;blank&rdquo;>paper</a>] [<a href="https://arxiv.org/abs/1806.05767" target=&ldquo;blank&rdquo;>arXiv</a>] [<a href="https://sites.google.com/view/mpnet/home" target=&ldquo;blank&rdquo;>project</a>]
</p>
</li><br/>

<li><p><b>Neural Path Planning: Fixed Time, Near-Optimal Path Generation via Oracle Imitation</b> <br />
  M.J.Bency, A.H.Qureshi, and M.C.Yip<br />
  IEEE/RSJ International Conference on Intelligent Robot and Systems (IROS), 2019.
[<a href="https://ieeexplore.ieee.org/document/8968089" target=&ldquo;blank&rdquo;>paper</a>] [<a href="https://arxiv.org/abs/1904.11102" target=&ldquo;blank&rdquo;>arXiv</a>] [<a href="https://github.com/mayurj747/oraclenet-analysis" target=&ldquo;blank&rdquo;>project</a>]
</p>
</li><br/>


<li><p><b>Machine Learning based Fixed-Time Optimal Path Generation</b> <br />
  M.C.Yip, M.J.Bency, and A.H.Qureshi<br />
  US Patent App. 16/222,706, 2019.
[<a href="https://patentimages.storage.googleapis.com/8e/d9/2c/e2cbb6710563ef/US20190184561A1.pdf" target=&ldquo;blank&rdquo;>paper</a>]
</p>
</li><br/>
</ul>

<h3>2018</h3>
<ul>
<li><p><b>Intrinsically motivated reinforcement learning for humanâ€“robot interaction in the real-world</b> <br />
  A.H.Qureshi, Y.Nakamura, Y.Yoshikawa, and H.Ishiguro<br />
  Neural Networks, 2018.
[<a href="https://www.sciencedirect.com/science/article/abs/pii/S0893608018301072" target=&ldquo;blank&rdquo;>paper</a>] [<a href="https://arxiv.org/abs/2008.03787" target=&ldquo;blank&rdquo;>arXiv</a>] 
</p>
</li><br/>

<li><p><b>Potentially guided bidirectionalized RRT* for fast optimal path planning in cluttered environments</b> <br />
  Z.Tahir, A.H.Qureshi, Y.Ayaz, and R.Nawaz<br />
  International Journal of Robotics and Autonomous Systems, 2018.
[<a href="https://www.sciencedirect.com/science/article/abs/pii/S0921889017309387" target=&ldquo;blank&rdquo;>paper</a>] [<a href="https://arxiv.org/abs/1807.08325" target=&ldquo;blank&rdquo;>arXiv</a>]
</p>
</li><br/>

<li><p><b>Deeply Informed Neural Sampling For Robot Motion Planning</b> <br />
  A.H.Qureshi and M.C.Yip <br />
  IEEE/RSJ International Conference on Intelligent Robot and Systems (IROS), 2018.
[<a href="https://ieeexplore.ieee.org/document/8593772" target=&ldquo;blank&rdquo;>paper</a>] [<a href="https://arxiv.org/abs/1809.10252" target=&ldquo;blank&rdquo;>arXiv</a>]
</p>
</li><br/>

<li><p><b>Adversarial Reward and Policy learning Via Variational Inverse Optimal Control</b> <br />
  A.H.Qureshi, and M.C.Yip<br />
  Bay Area Machine Learning Symposium, 2018.
</li><br/>


<li><p><b>Re-planning Using Delaunay Triangulation for Real Time Motion Planning in Complex Dynamic Environments</b> <br />
  A.H.Qureshi, Z.Tahir, G.Tariq, and Y.Ayaz<br />
  IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM), 2018.
[<a href="https://ieeexplore.ieee.org/document/8452685" target=&ldquo;blank&rdquo;>paper</a>]</p>
</li><br/>
</ul>

<h3>2017</h3>
<ul>
  <li><p><b>Deep reinforcement learning for human-robot interaction in the real-world</b> <br />
    A.H.Qureshi<br />
    M.S. Thesis, Osaka University, 2017.
  [<a href="https://www.researchgate.net/profile/Ahmed-Qureshi-4/publication/325615883_DEEP_REINFORCEMENT_LEARNING_FOR_HUMAN-ROBOT_INTERACTION_IN_THE_REAL-WORLD/links/5b1899bfaca272021cee2fce/DEEP-REINFORCEMENT-LEARNING-FOR-HUMAN-ROBOT-INTERACTION-IN-THE-REAL-WORLD.pdf" target=&ldquo;blank&rdquo;>paper</a>]</p>
  </li><br/>  

<li><p><b>Show, Attend and Interact: Perceivable Social Human-Robot Interaction through Neural Attention Q-Network</b> <br />
  A.H.Qureshi, Y.Nakamura, Y.Yoshikawa, and H.Ishiguro<br />
  IEEE/RAS International Conference on Robotics and Automation (ICRA), 2017.
[<a href="https://ieeexplore.ieee.org/document/7989193" target=&ldquo;blank&rdquo;>paper</a>] [<a href="https://arxiv.org/abs/1702.08626" target=&ldquo;blank&rdquo;>arXiv</a>]
</p>
</li><br/>
</ul>

<h3>2016</h3>
<ul>
<li><p><b>Robot gains social intelligence through multimodal deep reinforcement learning</b> <br />
  A.H.Qureshi, Y.Nakamura, Y.Yoshikawa, and H.Ishiguro<br />
  IEEE/RAS International Conference on Humanoid Robots, 2016.
[<a href="https://ieeexplore.ieee.org/document/7803357" target=&ldquo;blank&rdquo;>paper</a>] [<a href="https://arxiv.org/abs/1702.07492" target=&ldquo;blank&rdquo;>arXiv</a>]
</p>
</li><br/>
<li><p><b>Robot Learns Responsive Behavior through Interaction with People using Deep Reinforcement Learning</b> <br />
  A.H.Qureshi, Y.Nakamura, Y.Yoshikawa, and H.Ishiguro<br />
  International Symposium on Cognitive Neuroscience Robotics, 2016.
</p>
</li><br/>
</ul>


<h3>2015</h3>
<ul>
<li><p><b>Potential Functions Based Sampling Heuristic for Optimal Motion Planning</b> <br />
  A.H.Qureshi and Y.Ayaz<br />
  Autonomous Robots, 2015.
[<a href="https://link.springer.com/article/10.1007/s10514-015-9518-0" target=&ldquo;blank&rdquo;>paper</a>] [<a href="https://arxiv.org/abs/1704.00264" target=&ldquo;blank&rdquo;>arXiv</a>]
</p>
</li><br/>


<li><p><b>Intelligent Bidirectional Rapidly-Exploring Random Trees for Optimal Motion Planning in Complex Cluttered Environments</b> <br />
  A.H.Qureshi and Y.Ayaz<br />
  International Journal of Robotics and Autonomous Systems, 2015.
[<a href="https://www.sciencedirect.com/science/article/abs/pii/S0921889015000317" target=&ldquo;blank&rdquo;>paper</a>] [<a href="https://arxiv.org/abs/1703.08944" target=&ldquo;blank&rdquo;>arXiv</a>]
</p>
</li><br/>

<li><p><b>Triangular Geometrised Sampling Heuristic For RRT* Motion Planner</b> <br />
  A.H.Qureshi, S.Mumtaz, Y.Ayaz, O.Hasan, M.S.Muhammad, and M.T.Mahmood<br />
  International Journal of Advanced Robotic Systems (IJARS), 2015.
[<a href="https://journals.sagepub.com/doi/full/10.5772/59763" target=&ldquo;blank&rdquo;>paper</a>]
</p>
</li><br/>
<li><p><b>Collaborative optimal reciprocal collision avoidance for mobile robots</b> <br />
  S.A.Khan, Y.Ayaz, M.Jamil, S.O.Gillani, M.Naveed, A.H.Qureshi, and K.FIqbal<br />
  Journal of Control and Automation, 2015.
[<a href="http://article.nadiapub.com/IJCA/vol8_no8/21.pdf" target=&ldquo;blank&rdquo;>paper</a>]
</p>
</li><br/>
</ul>

<h3>2014</h3>
<ul>
  <li><p><b>Augmenting RRT*-Planner with Local Trees for Motion Planning in Complex Dynamic Environments</b> <br />
    A.H.Qureshi, S.Mumtaz, Y. Ayaz, and O. Hasan<br />
    IEEE/RAS International Conference on Methods and Models in Automation and Robotics (MMAR), 2014.
  [<a href="https://ieeexplore.ieee.org/document/6957432" target=&ldquo;blank&rdquo;>paper</a>]</p>
  </li><br/>

<li><p><b>Enhanced RRT* for Motion Planning in Complex Cluttered Environments</b> <br />
  A.H.Qureshi, and S.Mumtaz<br />
  B.S. Thesis, NUST, 2014.
</li><br/>
</ul>


<h3>2013</h3>
<ul>
  <li><p><b>Adaptive Potential Guided Directional RRT*</b> <br />
    A.H.Qureshi, S.Mumtaz, Y.Ayaz, O.Hasan, and W.Y.Kim<br />
    IEEE/RAS International Conference on Robotics and Biomimetics (ROBIO), 2013.
  [<a href="https://ieeexplore.ieee.org/document/6739744" target=&ldquo;blank&rdquo;>paper</a>]</p>
  </li><br/>

  <li><p><b>Human tracking by a mobile robot using 3D features</b> <br />
    B.Ali, A.H.Qureshi, Y.Ayaz, N.Muhammad, and W.Y.Kim<br />
    IEEE/RAS International Conference on Robotics and Biomimetics (ROBIO), 2013.
  [<a href="https://ieeexplore.ieee.org/document/6739841" target=&ldquo;blank&rdquo;>paper</a>]</p>
  </li><br/>

  <li><p><b>Potential guided directional-RRT* for accelerated motion planning in cluttered environments</b> <br />
    A.H.Qureshi, K.F.Iqbal, S.M.Qamar, F.Islam, Y.Ayaz, and N.Muhammad<br />
    IEEE/RAS International Conference on Mechatronics and Automation (ICMA), 2013.
  [<a href="https://ieeexplore.ieee.org/document/6617971" target=&ldquo;blank&rdquo;>paper</a>]</p>
  </li><br/>

  <li><p><b>A solution to Perceptual Aliasing through Probabilistic Fuzzy Logic and SIFT</b> <br />
    S.M.Qamar, K.F.Iqbal, A.H.Qureshi, N.Muhammad, Y.Ayaz, and A.G.Abbasi<br />
    IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM), 2013.
  [<a href="https://ieeexplore.ieee.org/document/6584289" target=&ldquo;blank&rdquo;>paper</a>]</p>
  </li><br/>



</ul>


</td>
</tr>
</table>
</body>
</html>
